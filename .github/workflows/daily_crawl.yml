name: Daily KNU Info Crawl & Ingest

on:
  schedule:
    - cron: '0 21 * * *'  # KST 06:00
  workflow_dispatch:

jobs:
  crawl-and-ingest:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directories
      run: |
        mkdir -p data/notices
        mkdir -p data/images
        mkdir -p data/schedules

    - name: Run Notice Crawler
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        python src/crawl/crawl_notice.py

    - name: Run Schedule Crawler
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        python src/crawl/crawl_schedule.py

    - name: Run Curriculum Crawler
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        python src/crawl/crawl_curriculum.py

    - name: Run Ingestion to Qdrant
      env:
        QDRANT_URL: ${{ secrets.QDRANT_URL }}
        QDRANT_API_KEY: ${{ secrets.QDRANT_API_KEY }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        PYTHONPATH: ${{ github.workspace }}
      run: |
        python src/etl/ingestion.py

    - name: Upload crawled data as artifacts
      uses: actions/upload-artifact@v3
      with:
        name: crawled-data
        path: data/
        retention-days: 7

    - name: Commit and push data (optional)
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        git diff --quiet && git diff --staged --quiet || (git commit -m "Auto-update crawled data" && git push)
      continue-on-error: true